# Proyecto de Interacción Humano Computador
## Asistente de Traducción de Lengua de Señas en Tiempo Real con Cámaras y Detección de Manos

<p align="center">
  <img src="img/img_logo.png" alt="Logo del Proyecto" width="200">
</p>

# Principios de Gestalt del Logo:

- **Proximidad**: Los diferentes elementos del logo (las líneas que representan la mano y la forma de la cámara) están agrupados de manera cercana, lo que hace que el cerebro los perciba como parte de una misma figura.

- **Similitud**: Las líneas que conforman la mano son del mismo color, de esta manera se evita confusión con la cámara.

- **Figura y Fondo**: Se distingue claramente la figura (una cámara sostenida por una mano) del fondo blanco. La cámara y la mano se perciben como un conjunto gracias a los contrastes, resaltando el objeto principal sobre el fondo.

- **Simetría**: Podemos ver una mano en el logo, pese a que solo son líneas, el cerebro reduce la complejidad de la forma para ver una figura más simple.

- **Continuidad**: Las líneas que componen la mano parecen fluir detrás de la cámara de una manera continua. El cerebro sigue estas líneas, lo que da la sensación de que la mano sostiene la cámara.

- **Cierre**: Aunque la forma de la cámara y de la mano no está completamente delineada, el cerebro completa las partes faltantes para reconocer ambas figuras. Esto se debe a que nuestros cerebros tienden a cerrar las formas incompletas.


### Realizado por:
- Sergio Mena
- Saul Condori
- Christian Pardavé

---

## Etapa 1: Propuesta del Proyecto



### 1. Introducción
La barrera de comunicación entre personas sordas y oyentes sigue siendo un desafío significativo, ya que muchos oyentes no están familiarizados con el lenguaje de señas. Este proyecto, **Asistente de Traducción de Lengua de Señas con Cámara y Detección de Manos**, busca utilizar la visión computacional para traducir el lenguaje de señas a texto o voz en tiempo real, facilitando la interacción entre personas sordas y oyentes. Usando cámaras y algoritmos de detección de manos, el sistema ofrecerá una solución accesible y sin la necesidad de dispositivos físicos adicionales como guantes inteligentes.

### 2. Planteamiento del problema
Para las personas sordas, la comunicación con personas que no saben lenguaje de señas puede ser difícil y, a menudo, frustrante. Esta barrera se agrava en contextos donde la comunicación inmediata es crucial, como en atención médica, educación o servicios públicos. Aunque existen soluciones como intérpretes de señas o tecnologías asistivas, estas no siempre son accesibles o prácticas. Este proyecto plantea una solución que, mediante cámaras y algoritmos avanzados, permita interpretar el lenguaje de señas de forma eficiente y accesible, sin la necesidad de dispositivos adicionales.

### 3. Objetivos
El objetivo del proyecto es desarrollar un sistema basado en cámaras para la traducción automática del lenguaje de señas a texto o voz. Utilizando técnicas de detección de manos y visión por computadora, el sistema ofrecerá una solución precisa, accesible y en tiempo real, mejorando la interacción entre personas sordas y oyentes. El diseño de la interfaz se basará en principios de Interacción Humano-Computadora (HCI), asegurando una experiencia fluida para ambos tipos de usuarios. Los objetivos se ajustarán durante el desarrollo según el feedback de las pruebas de usabilidad con los usuarios.

### 4. Público Objetivo
El público objetivo se divide en dos grupos principales:

- **Personas sordas o con discapacidad auditiva**: Quienes utilizarán el sistema para traducir su lenguaje de señas a texto o voz, facilitando la comunicación en situaciones cotidianas o críticas.
- **Personas oyentes no familiarizadas con el lenguaje de señas**: Usuarios como profesionales en servicios de atención al cliente, personal médico, o cualquier persona que desee comunicarse con personas sordas de manera eficiente.

Además, el sistema estará diseñado para ser inclusivo, considerando diferentes edades, habilidades tecnológicas y contextos de uso, con el objetivo de que sea adoptado por un amplio espectro de usuarios.

### 5. Qué hará el proyecto
El proyecto implementará un sistema de reconocimiento de lenguaje de señas mediante visión computacional. Algunas de sus funcionalidades clave incluyen:

- **Traducción en tiempo real**: El sistema detectará las manos del usuario y reconocerá sus movimientos para traducir señas a texto o voz de manera instantánea.
- **Interfaz personalizable**: Los usuarios podrán elegir entre distintas configuraciones, como el idioma, la sensibilidad de la detección, y la velocidad de la traducción.
- **Integración con dispositivos móviles**: El sistema estará disponible en smartphones y tablets, facilitando su portabilidad y adopción en distintos contextos.
- **Accesibilidad sin dispositivos adicionales**: A diferencia de los guantes inteligentes, este sistema solo requerirá una cámara para funcionar, reduciendo costos y haciendo la tecnología más accesible.

El enfoque será innovador y creativo, asegurando que la interfaz sea interactiva, intuitiva y altamente funcional.

### 6. Análisis de sistemas existentes
Una de las soluciones comparables es **HandTalk**, una aplicación que traduce lenguaje de señas mediante animaciones 3D de un avatar. Si bien esta aplicación ha sido útil para algunos usuarios, presenta limitaciones significativas.

- **Aspectos positivos**: HandTalk ha facilitado la comunicación a través de un avatar que traduce de texto a señas, siendo una herramienta educativa útil.
- **Aspectos negativos**: El sistema no funciona en tiempo real con señas hechas por los usuarios. Además, la traducción depende del input de texto, lo que no permite una interacción completamente fluida. El uso de un avatar limita su capacidad de interpretar una amplia variedad de gestos y expresiones faciales, que son esenciales en el lenguaje de señas.
